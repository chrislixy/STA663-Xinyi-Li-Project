{
 "metadata": {
  "name": "",
  "signature": "sha256:5ddf11b640995462e22a8b35ffbdc0c2228fb25ecc8757f1c5b3925baf1c4b10"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Choice of Paper"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hierarchical Topic Models and the Nested Chinese Restaurant Process"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This paper describes hierarchical Chinese Restaurant Process and proposes Bayesian statistics with Gibbs Sampler to solve the problem. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are infinite number of inifinite-table Chinese restaurant in a city. On each table, there is a card that refer to another restaurant. \n",
      "\n",
      "For example, a person to go one restaurant on day 1, which we refer as root restaurant, and choose a table with some probability. We set it to be level 1. Then, on day 2, he follows the card which he gets from root restaurant to go to the second restaurant. This is level 2. The process repeats. After forming the L-level path, we draw words from the L topics which are associated with the root along that path.\n",
      "\n",
      "The process can be expressed as follow:\n",
      "\n",
      "- Let c_1 be the root restaurant.\n",
      "- For each level $\\ell\\in\\{2,...,L\\}$:\n",
      "  - Draw a table from restaurant $c_{l-1}$ with $P(occupied\\ table\\ i|previous\\ customers)=\\frac{m_i}{\\gamma+m_i-1}$ and $P(next\\ occupied\\ table\\ i|previous\\ customers)=\\frac{\\gamma}{\\gamma+m_i-1}$.\n",
      "  - Set $c_l$ to be the restaurant referred to by that table.\n",
      "- Draw an $L$-dimensional topic proportion vector $\\theta$ from Dir($\\alpha$)\n",
      "- For each word $n\\in\\{1,...,N\\}$:\n",
      "  - Draw $z\\in\\{1,...,L\\}$ from Mult($\\theta$)\n",
      "  - Draw $w_n$ from the topic associated with restaurant $c_z$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Method"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gibbs Sampling"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Application"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Semantic processing?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Advantage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With enough computational power, we can simulate the process as many times as we want, and thus get a precise approximation of the true parameters."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}